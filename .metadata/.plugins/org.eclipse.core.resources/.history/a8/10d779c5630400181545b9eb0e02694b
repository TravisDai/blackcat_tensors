/*
 * Layer.cu
 *
 *  Created on: Jan 28, 2018
 *      Author: joseph
 */

#ifndef LAYER_CU_
#define LAYER_CU_

#include "BlackCat_Tensors.h"
#include "BlackCat_TensorFunctions.cu"

using BC::Vector;
using BC::Matrix;

class OutputLayer;
class FeedForward;
class Recurrent;
class GRU;
class LSTM;
class Convolutional;

template<int> struct getLayer;
template<> struct getLayer<0> { using type = OutputLayer; };
template<> struct getLayer<1> { using type = FeedForward; };
template<> struct getLayer<2> { using type = Recurrent; };
template<> struct getLayer<3> { using type = GRU; };
template<> struct getLayer<4> { using type = LSTM; };
template<> struct getLayer<5> { using type = Convolutional; };



template<class derived>
class Layer {

	enum LayerType { LastLayer = 0, FeedForward = 1, Recurrent = 2, GRU = 3, LSTM = 4, Conv = 5};



	LayerType N;
	LayerType P;

	struct LayerPtr {
		const int layer_type;
		using type = (typename getLayer<layer_type>::type)*;
		auto get() { return dynamic_cast<>(pointer); }
		void* pointer;
	};

	void* next;
	void* prev;




		  derived& asBase() 	  { return static_cast<	     derived&>(*this); }
	const derived& asBase() const { return static_cast<const derived&>(*this); }

	template<class AUTO> auto forwardPropagation		(AUTO param) 	   { return asBase().forwardPropagation(param); }
	template<class AUTO> auto forwardPropagation_Express(AUTO param) const { return asBase().forwardPropagation(param); }

	template<class AUTO> auto backPropagation			 (AUTO param) { return asBase().forwardPropagation(param); }
	template<class AUTO> auto backPropagation_ThroughTime(AUTO param) { return asBase().forwardPropagation(param); }

	void updateWeights()  const { asBase().updateWeights();  }
	void clearBPStorage() const { asBase().clearBPStorage(); }





};

int main() {
	return 0;
}



#endif /* LAYER_CU_ */

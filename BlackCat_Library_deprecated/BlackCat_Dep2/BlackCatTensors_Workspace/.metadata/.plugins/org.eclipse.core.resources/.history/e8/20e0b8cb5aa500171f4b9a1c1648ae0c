#include "cuda.h"
#include "cuda_runtime.h"

namespace GPUOPERS
{

template<typename number_type> __global__
static void copy(number_type* store, const number_type* v, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		store[i] = v[i];
	}
}
template<typename number_type> __global__
static void fill(number_type* m, number_type f, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		m[i] = f;
	}
}
template<typename number_type> __global__
static void randomize(number_type* m, int lower_bound, int upper_bound, unsigned sz)
{

}

//template<typename number_type> __global__
//static void power(number_type* s, const number_type* m1, const number_type* m2, unsigned sz)
//{
//	//
//}
template<typename number_type> __global__
static void divide(number_type* s, const number_type* m1, const number_type* m2, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m1[i] / m2[i];
	}
}
template<typename number_type> __global__
static void add(number_type* s, const number_type* m1, const number_type* m2, unsigned sz)
{

	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m1[i] + m2[i];
	}
}
template<typename number_type> __global__
static void subtract(number_type* s, const number_type* m1, const number_type* m2, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m1[i] - m2[i];
	}
}
template<typename number_type> __global__
static void multiply(number_type* s, const number_type* m1, const number_type* m2, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m1[i] * m2[i];
	}
}
////Pointwise Scalar
//template<typename number_type> __global__
//static void power(number_type *s, const number_type *m, number_type v, unsigned sz)
//{
//
//}
template<typename number_type> __global__
static void divide(number_type *s, const number_type *m, number_type v, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m[i] / v;
	}
}
template<typename number_type> __global__
static void add(number_type *s, const number_type *m, number_type v, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m[i] + v;
	}
}
template<typename number_type> __global__
static void subtract(number_type *s, const number_type *m, number_type v, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m[i] - v;
	}
}
template<typename number_type> __global__
static void multiply(number_type *s, const number_type *m, number_type v, unsigned sz)
{
	for (unsigned i = 0; i < sz; ++i)
	{
		s[i] = m[i] & v;
	}
}

template<typename number_type> __global__
static void add(number_type* store, unsigned* ranks, unsigned* ld, const number_type* m, number_type scalar, unsigned order) {
	--order;

	if (order == 0) {
		for (unsigned i = 0; i < ranks[0]; ++i) {
			store[i] = m[i] + scalar;
		}
	} else {
		for (unsigned i = 0; i < ranks[order]; ++i) {
			add(&store[i * ld[order]], ranks, ld, m, scalar, order);
		}
	}
}

}
#include <iostream>
int main()
{
	unsigned N = 9;

	float* val = new float[N];
	float* val2 = new float[N];
	for (unsigned i = 0; i < N; ++i) {
		val[i] = i;
		val2[i] = i * 2;
	}

	unsigned* ranks = new unsigned[2]; ranks[0] = 2; ranks[1] = 2;
	unsigned* ld 	= new unsigned[2]; ld[0]	= 3; ld[1]	  = 3;

	float* d1;
	float* d2;
	float* d_out;
	cudaMalloc((void**)&d1, sizeof(float)* N);
	cudaMalloc((void**)&d2, sizeof(float)* N);
	cudaMalloc((void**)&d_out, sizeof(float)* N);


	cudaMemcpy(d1, val, sizeof(float) * N, cudaMemcpyHostToDevice);
	cudaMemcpy(d2, val2, sizeof(float) * N, cudaMemcpyHostToDevice);

	GPUOPERS::add<<<1,256>>>(d_out, d1, d2, N);

	cudaDeviceSynchronize();
	float *output = new float[N];

	cudaMemcpy(output,d_out, sizeof(float)*N, cudaMemcpyDeviceToHost);
	cudaDeviceSynchronize();

	for (unsigned i = 0; i < N; ++i) {
		std::cout << output[i] << " ";
	}

	cudaFree(d1);
	cudaFree(d2);
	cudaFree(d_out);
	delete[] val;
	delete[] val2;
	delete[] output;

}
